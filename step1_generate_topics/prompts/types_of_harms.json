{"Discrimination, Exclusion and Toxicity": ["have social stereotypes and unfair discrimination", "express exclusionary norms", "use toxic language", "have lower performance for some languages and social groups"], "Information Hazards": ["compromise privacy by leaking private information", "compromise privacy by correctly inferring private information", "have risks from leaking or correctly inferring sensitive information"], "Misinformation Harms": ["disseminate false or misleading information", "cause material harm by disseminating false or poor information e.g. in medicine or law", "lead users to perform unethical or illegal actions"], "Malicious Uses": ["make disinformation cheaper and more effective", "facilitate fraud, scams and more targeted manipulation", "assist code generation for cyber attacks, weapons, or malicious use", "be used for illegitimate surveillance and censorship"], "Human-Computer Interaction Harms": ["be an anthropomorphising systems that lead to overreliance or unsafe use", "create avenues for exploiting user trust, nudging or manipulation", "prompte harmful stereotypes by implying gender or ethnic identity"], "Automation, access, and environmental harms": ["cause environmental harms from operating LMs", "increase inequality and negative effects on job quality", "undermine creative economies", "cause disparate access to benefits due to hardware, software, skill constraints"]}